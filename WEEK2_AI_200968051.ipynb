{
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# MOHD ARHAM SHAIKH\n",
        "# 200968051\n",
        "# BATCH 3"
      ],
      "metadata": {
        "id": "xn2jjr7KKKtO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tf-agents[reverb]\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\nCollecting tf-agents[reverb]\n  Downloading tf_agents-0.15.0-py3-none-any.whl (1.4 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.4/1.4 MB\u001b[0m \u001b[31m52.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: absl-py>=0.6.1 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (1.4.0)\nRequirement already satisfied: cloudpickle>=1.3 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (2.2.1)\nCollecting tensorflow-probability>=0.18.0\n  Downloading tensorflow_probability-0.19.0-py2.py3-none-any.whl (6.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.7/6.7 MB\u001b[0m \u001b[31m85.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: protobuf>=3.11.3 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (3.19.6)\nRequirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (1.15.0)\nCollecting pygame==2.1.0\n  Downloading pygame-2.1.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (18.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m18.3/18.3 MB\u001b[0m \u001b[31m75.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: pillow in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (7.1.2)\nRequirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (1.14.1)\nRequirement already satisfied: numpy>=1.13.3 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (1.21.6)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (4.4.0)\nCollecting gym<=0.23.0,>=0.17.0\n  Downloading gym-0.23.0.tar.gz (624 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m624.4/624.4 KB\u001b[0m \u001b[31m54.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\nRequirement already satisfied: gin-config>=0.4.0 in /usr/local/lib/python3.8/dist-packages (from tf-agents[reverb]) (0.5.0)\nCollecting rlds\n  Downloading rlds-0.1.7-py3-none-manylinux2010_x86_64.whl (48 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m48.4/48.4 KB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting dm-reverb~=0.10.0\n  Downloading dm_reverb-0.10.0-cp38-cp38-manylinux2014_x86_64.whl (6.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.3/6.3 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting tensorflow==2.11.0\n  Downloading tensorflow-2.11.0-cp38-cp38-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (588.3 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m588.3/588.3 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (3.3.0)\nRequirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (0.4.0)\nCollecting tensorflow-estimator<2.12,>=2.11.0\n  Downloading tensorflow_estimator-2.11.0-py2.py3-none-any.whl (439 kB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.2/439.2 KB\u001b[0m \u001b[31m41.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (1.51.1)\nCollecting tensorboard<2.12,>=2.11\n  Downloading tensorboard-2.11.2-py3-none-any.whl (6.0 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m96.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hCollecting keras<2.12,>=2.11.0\n  Downloading keras-2.11.0-py2.py3-none-any.whl (1.7 MB)\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.7/1.7 MB\u001b[0m \u001b[31m76.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hRequirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (1.6.3)\nRequirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (15.0.6.1)\nCollecting flatbuffers>=2.0\n  Downloading flatbuffers-23.1.21-py2.py3-none-any.whl (26 kB)\nRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (23.0)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (57.4.0)\nRequirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (0.2.0)\nRequirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (2.2.0)\nRequirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (0.30.0)\nRequirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.8/dist-packages (from tensorflow==2.11.0->tf-agents[reverb]) (3.1.0)\nRequirement already satisfied: dm-tree in /usr/local/lib/python3.8/dist-packages (from dm-reverb~=0.10.0->tf-agents[reverb]) (0.1.8)\nRequirement already satisfied: portpicker in /usr/local/lib/python3.8/dist-packages (from dm-reverb~=0.10.0->tf-agents[reverb]) (1.3.9)\nRequirement already satisfied: importlib-metadata>=4.10.0 in /usr/local/lib/python3.8/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (6.0.0)\nRequirement already satisfied: gym-notices>=0.0.4 in /usr/local/lib/python3.8/dist-packages (from gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (0.0.8)\nRequirement already satisfied: decorator in /usr/local/lib/python3.8/dist-packages (from tensorflow-probability>=0.18.0->tf-agents[reverb]) (4.4.2)\nRequirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.8/dist-packages (from astunparse>=1.6.0->tensorflow==2.11.0->tf-agents[reverb]) (0.38.4)\nRequirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.8/dist-packages (from importlib-metadata>=4.10.0->gym<=0.23.0,>=0.17.0->tf-agents[reverb]) (3.12.0)\nRequirement already satisfied: tensorboard-data-server<0.7.0,>=0.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (0.6.1)\nRequirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (2.16.0)\nRequirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (1.0.1)\nRequirement already satisfied: google-auth-oauthlib<0.5,>=0.4.1 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (0.4.6)\nRequirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (2.25.1)\nRequirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (3.4.1)\nRequirement already satisfied: tensorboard-plugin-wit>=1.6.0 in /usr/local/lib/python3.8/dist-packages (from tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (1.8.1)\nRequirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (4.9)\nRequirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (5.3.0)\nRequirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.8/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (0.2.8)\nRequirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.8/dist-packages (from google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (1.3.1)\nRequirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (2.10)\nRequirement already satisfied: chardet<5,>=3.0.2 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (4.0.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (2022.12.7)\nRequirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.8/dist-packages (from requests<3,>=2.21.0->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (1.24.3)\nRequirement already satisfied: pyasn1<0.5.0,>=0.4.6 in /usr/local/lib/python3.8/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (0.4.8)\nRequirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.8/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<0.5,>=0.4.1->tensorboard<2.12,>=2.11->tensorflow==2.11.0->tf-agents[reverb]) (3.2.2)\nBuilding wheels for collected packages: gym\n  Building wheel for gym (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n  Created wheel for gym: filename=gym-0.23.0-py3-none-any.whl size=697659 sha256=3cdcb3f7296b1ea80b78d3861b748cb64580d079dacf3649a390cc0c70fbae65\n  Stored in directory: /root/.cache/pip/wheels/e7/2f/ab/68bf956c5dde73c1856d981e54292cf58385fb60bca10b7acd\nSuccessfully built gym\nInstalling collected packages: flatbuffers, tensorflow-probability, tensorflow-estimator, rlds, pygame, keras, dm-reverb, gym, tf-agents, tensorboard, tensorflow\n  Attempting uninstall: flatbuffers\n    Found existing installation: flatbuffers 1.12\n    Uninstalling flatbuffers-1.12:\n      Successfully uninstalled flatbuffers-1.12\n  Attempting uninstall: tensorflow-probability\n    Found existing installation: tensorflow-probability 0.17.0\n    Uninstalling tensorflow-probability-0.17.0:\n      Successfully uninstalled tensorflow-probability-0.17.0\n  Attempting uninstall: tensorflow-estimator\n    Found existing installation: tensorflow-estimator 2.9.0\n    Uninstalling tensorflow-estimator-2.9.0:\n      Successfully uninstalled tensorflow-estimator-2.9.0\n  Attempting uninstall: keras\n    Found existing installation: keras 2.9.0\n    Uninstalling keras-2.9.0:\n      Successfully uninstalled keras-2.9.0\n  Attempting uninstall: gym\n    Found existing installation: gym 0.25.2\n    Uninstalling gym-0.25.2:\n      Successfully uninstalled gym-0.25.2\n  Attempting uninstall: tensorboard\n    Found existing installation: tensorboard 2.9.1\n    Uninstalling tensorboard-2.9.1:\n      Successfully uninstalled tensorboard-2.9.1\n  Attempting uninstall: tensorflow\n    Found existing installation: tensorflow 2.9.2\n    Uninstalling tensorflow-2.9.2:\n      Successfully uninstalled tensorflow-2.9.2\nSuccessfully installed dm-reverb-0.10.0 flatbuffers-23.1.21 gym-0.23.0 keras-2.11.0 pygame-2.1.0 rlds-0.1.7 tensorboard-2.11.2 tensorflow-2.11.0 tensorflow-estimator-2.11.0 tensorflow-probability-0.19.0 tf-agents-0.15.0\n"
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKLhP22HHzmE",
        "outputId": "4346a02c-e62d-4d01-ec33-caae01a93c2f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from __future__ import absolute_import\n",
        "from __future__ import division\n",
        "from __future__ import print_function\n",
        "\n",
        "import abc\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "\n",
        "from tf_agents.environments import py_environment\n",
        "from tf_agents.environments import tf_environment\n",
        "from tf_agents.environments import tf_py_environment\n",
        "from tf_agents.environments import utils\n",
        "from tf_agents.specs import array_spec\n",
        "from tf_agents.environments import wrappers\n",
        "from tf_agents.environments import suite_gym\n",
        "from tf_agents.trajectories import time_step as ts"
      ],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "usClksf7LD51"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = suite_gym.load('CartPole-v0')\n",
        "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
        "\n",
        "print(isinstance(tf_env, tf_environment.TFEnvironment))\n",
        "print(\"TimeStep Specs:\", tf_env.time_step_spec())\n",
        "print(\"Action Specs:\", tf_env.action_spec())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "True\nTimeStep Specs: TimeStep(\n{'discount': BoundedTensorSpec(shape=(), dtype=tf.float32, name='discount', minimum=array(0., dtype=float32), maximum=array(1., dtype=float32)),\n 'observation': BoundedTensorSpec(shape=(4,), dtype=tf.float32, name='observation', minimum=array([-4.8000002e+00, -3.4028235e+38, -4.1887903e-01, -3.4028235e+38],\n      dtype=float32), maximum=array([4.8000002e+00, 3.4028235e+38, 4.1887903e-01, 3.4028235e+38],\n      dtype=float32)),\n 'reward': TensorSpec(shape=(), dtype=tf.float32, name='reward'),\n 'step_type': TensorSpec(shape=(), dtype=tf.int32, name='step_type')})\nAction Specs: BoundedTensorSpec(shape=(), dtype=tf.int64, name='action', minimum=array(0), maximum=array(1))\n"
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GoPusE__KeR4",
        "outputId": "f1bc6ee3-5183-4201-fe22-9af8e3d3bb79"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = suite_gym.load('CartPole-v0')\n",
        "\n",
        "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
        "# reset() creates the initial time_step after resetting the environment.\n",
        "time_step = tf_env.reset()\n",
        "num_steps = 3\n",
        "transitions = []\n",
        "reward = 0\n",
        "for i in range(num_steps):\n",
        "  action = tf.constant([i % 2])\n",
        "  # applies the action and returns the new TimeStep.\n",
        "  next_time_step = tf_env.step(action)\n",
        "  transitions.append([time_step, action, next_time_step])\n",
        "  reward += next_time_step.reward\n",
        "  time_step = next_time_step\n",
        "\n",
        "np_transitions = tf.nest.map_structure(lambda x: x.numpy(), transitions)\n",
        "print('\\n'.join(map(str, np_transitions)))\n",
        "print('Total reward:', reward.numpy())"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "[TimeStep(\n{'discount': array([1.], dtype=float32),\n 'observation': array([[ 0.04975086, -0.00748077,  0.0303786 , -0.01969212]],\n      dtype=float32),\n 'reward': array([0.], dtype=float32),\n 'step_type': array([0], dtype=int32)}), array([0], dtype=int32), TimeStep(\n{'discount': array([1.], dtype=float32),\n 'observation': array([[ 0.04960125, -0.20302491,  0.02998476,  0.2824187 ]],\n      dtype=float32),\n 'reward': array([1.], dtype=float32),\n 'step_type': array([1], dtype=int32)})]\n[TimeStep(\n{'discount': array([1.], dtype=float32),\n 'observation': array([[ 0.04960125, -0.20302491,  0.02998476,  0.2824187 ]],\n      dtype=float32),\n 'reward': array([1.], dtype=float32),\n 'step_type': array([1], dtype=int32)}), array([1], dtype=int32), TimeStep(\n{'discount': array([1.], dtype=float32),\n 'observation': array([[ 0.04554075, -0.0083432 ,  0.03563313, -0.0006584 ]],\n      dtype=float32),\n 'reward': array([1.], dtype=float32),\n 'step_type': array([1], dtype=int32)})]\n[TimeStep(\n{'discount': array([1.], dtype=float32),\n 'observation': array([[ 0.04554075, -0.0083432 ,  0.03563313, -0.0006584 ]],\n      dtype=float32),\n 'reward': array([1.], dtype=float32),\n 'step_type': array([1], dtype=int32)}), array([0], dtype=int32), TimeStep(\n{'discount': array([1.], dtype=float32),\n 'observation': array([[ 0.04537389, -0.20395759,  0.03561997,  0.30305085]],\n      dtype=float32),\n 'reward': array([1.], dtype=float32),\n 'step_type': array([1], dtype=int32)})]\nTotal reward: [3.]\n"
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KRwp5fkwKe5m",
        "outputId": "ab54dc5c-ee0d-4878-ba70-003e605bb6e1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "env = suite_gym.load('CartPole-v0')\n",
        "tf_env = tf_py_environment.TFPyEnvironment(env)\n",
        "\n",
        "time_step = tf_env.reset()\n",
        "rewards = []\n",
        "steps = []\n",
        "num_episodes = 5\n",
        "\n",
        "for _ in range(num_episodes):\n",
        "  episode_reward = 0\n",
        "  episode_steps = 0\n",
        "  while not time_step.is_last():\n",
        "    action = tf.random.uniform([1], 0, 2, dtype=tf.int32)\n",
        "    time_step = tf_env.step(action)\n",
        "    episode_steps += 1\n",
        "    episode_reward += time_step.reward.numpy()\n",
        "  rewards.append(episode_reward)\n",
        "  steps.append(episode_steps)\n",
        "  time_step = tf_env.reset()\n",
        "\n",
        "num_steps = np.sum(steps)\n",
        "avg_length = np.mean(steps)\n",
        "avg_reward = np.mean(rewards)\n",
        "\n",
        "print('num_episodes:', num_episodes, 'num_steps:', num_steps)\n",
        "print('avg_length', avg_length, 'avg_reward:', avg_reward)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "num_episodes: 5 num_steps: 115\navg_length 23.0 avg_reward: 23.0\n"
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rcA-5b_tLR_E",
        "outputId": "0b6ed19f-76fc-40fe-ed45-8eff7110965f"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import gym\n",
        "import numpy as np\n",
        "\n",
        "# a. Implement the CartPole environment for a certain number of steps\n",
        "def run_steps(steps):\n",
        "    env = gym.make('CartPole-v1')\n",
        "    total_reward = 0\n",
        "    observation = env.reset()\n",
        "    for step in range(steps):\n",
        "        #env.render()\n",
        "        action = env.action_space.sample() # sample random action\n",
        "        observation, reward, done, info = env.step(action)\n",
        "        total_reward += reward\n",
        "        if done:\n",
        "            break\n",
        "    env.close()\n",
        "    return total_reward\n",
        "\n",
        "# b. Implement the CartPole environment for a certain number of episodes\n",
        "def run_episodes(episodes):\n",
        "    env = gym.make('CartPole-v0')\n",
        "    total_rewards = []\n",
        "    for episode in range(episodes):\n",
        "        observation = env.reset()\n",
        "        episode_reward = 0\n",
        "        while True:\n",
        "            #env.render()\n",
        "            action = env.action_space.sample() # sample random action\n",
        "            observation, reward, done, info = env.step(action)\n",
        "            episode_reward += reward\n",
        "            if done:\n",
        "                total_rewards.append(episode_reward)\n",
        "                break\n",
        "    env.close()\n",
        "    return total_rewards\n",
        "\n",
        "# c. Compare and comment on the rewards earned for both approaches\n",
        "steps = 200\n",
        "episodes = 10\n",
        "\n",
        "reward_steps = run_steps(steps)\n",
        "rewards_episodes = run_episodes(episodes)\n",
        "\n",
        "print(f\"Reward after {steps} steps: {reward_steps}\")\n",
        "print(f\"Rewards after {episodes} episodes: {rewards_episodes}\")\n",
        "print(f\"Average reward after {episodes} episodes: {np.mean(rewards_episodes)}\")\n"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Reward after 200 steps: 37.0\nRewards after 10 episodes: [18.0, 11.0, 10.0, 21.0, 27.0, 13.0, 59.0, 15.0, 11.0, 18.0]\nAverage reward after 10 episodes: 20.3\n"
        }
      ],
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MYhmePgxLVl1",
        "outputId": "6eb68919-f852-4903-af53-40fb6a7b8c26"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The rewards of the first approach taken 200 steps is 37.0 which is more than the rewards of the second aproach taken 10 episodes 20.3"
      ],
      "metadata": {
        "id": "4OlQkvecoMZW"
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "id": "NYgg2LmYoeCK"
      }
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python",
      "language": "python",
      "display_name": "Pyolite (preview)"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "python",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8"
    },
    "kernel_info": {
      "name": "python"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}